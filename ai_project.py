# -*- coding: utf-8 -*-
"""AI_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11lc_cXm6WlTbwZGvEgJvZHzMf0dvWPyB
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install lion-pytorch

# Commented out IPython magic to ensure Python compatibility.
# %pip install opencv-python

from google.colab import files
files.upload()

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q kaggle

# Commented out IPython magic to ensure Python compatibility.
# %mkdir -p ~/.kaggle

# Commented out IPython magic to ensure Python compatibility.
# %cp kaggle.json ~/.kaggle/

!kaggle datasets list -s 'noamsegal/affectnet-training-data'

! kaggle datasets download noamsegal/affectnet-training-data

! unzip '/content/affectnet-training-data.zip'

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
from keras import Sequential
from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D
from keras.metrics import MeanIoU
from keras.losses import SparseCategoricalCrossentropy
from keras.utils import load_img, img_to_array
# from tensorflow_addons.optimizers import AdamW
from sklearn.metrics import confusion_matrix
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report
import os
import torch 
from torch import nn
from lion_pytorch import Lion
import cv2
from os.path import join
import tensorflow as tf
from PIL import Image

path = ('/content/affectnet-training-data/')
file = (path + 'labels.csv')
df = pd.read_csv(file)

df.dtypes

df['pth']

len(df['pth'])

df['label']

picture_size = 96
images = np.ndarray(shape=(28175, 96, 96, 3), dtype=int) #rgb

imagesg = np.ndarray(shape=(28175, 96, 96, 1), dtype=int) #gray
folder_path = "/content/affectnet-training-data/"
expression = 'happy'

plt.figure(figsize=(12, 12))
for i in range(1, 10, 1):
    plt.subplot(3, 3, i)
    img = load_img(folder_path + expression + "/" +
                   os.listdir(folder_path + expression)[i], target_size=(picture_size, picture_size))
    img = img.convert('L')  #to pillow convert it to gray scale
    imagesg[i] = img_to_array(img) 
    plt.imshow(img,cmap='gray')  #to matplotlip convert it to gray
plt.show()

plt.imshow(imagesg[1],cmap="gray")

plt.figure(figsize=(12, 12))
for i in range(0, len(df)):
    # plt.subplot(3, 3, i)
    img = load_img(folder_path + df['pth'][i], target_size=(picture_size, picture_size))
    img = img.convert('L')  #to pillow convert it to gray scale
    imagesg[i] = img_to_array(img) 
    # plt.imshow(img,cmap='gray')  #to matplotlip convert it to gray
# plt.show()

label=[]
labels=[]
for i in range(0,len(df['pth'])):
    label=df['pth'][i].split("/")[0]
    labels.append(label)
df2=pd.DataFrame(labels)

#df2.rename(columns={df2[:1]:'label'},inplace=True)
df2.columns=["label"]

df2

df = pd.merge(df["pth"],df2["label"], how ='right', left_index=True, right_index=True)

df

df['label']=df['label'].astype('category')
df['label']=df['label'].cat.codes
df

df.info()

x=imagesg
y=df['label']
x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=1)

"""# New Section"""

from keras.optimizers import Adam,SGD,RMSprop
from keras.losses import SparseCategoricalCrossentropy

batch_size  = 32

no_of_classes = 8

model = Sequential()

#1st CNN layer
model.add(Conv2D(64, (3,3), padding="same", activation='selu', input_shape = (picture_size,picture_size,1), kernel_regularizer='l2'))
model.add(Conv2D(64, (3,3), padding="same", activation='selu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2), strides = 2))
model.add(Dropout(0.40))

#2nd CNN layer
model.add(Conv2D(128, (3,3), padding="same", activation='selu'))
model.add(BatchNormalization())
model.add(Conv2D(128, (3,3), padding="same", activation='selu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2), strides = 2))
model.add(Dropout(0.40))

#3rd CNN layer
model.add(Conv2D(256, (3,3), padding="same", activation='selu'))
model.add(BatchNormalization())
model.add(Conv2D(256, (3,3), padding="same", activation='selu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2), strides = 2))
model.add(Dropout(0.40))

#4th CNN layer
model.add(Conv2D(512, (3,3), padding="same", activation='selu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2), strides = 2))
model.add(Dropout(0.40))

# 5th CNN layer
model.add(Conv2D(1024, (3,3), padding="same", activation='selu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout(0.40))

model.add(Flatten())

# Fully connected 1st layer
model.add(Dense(128, activation='selu'))
model.add(Dropout(0.50))

#Fully connected 2nd layer
model.add(Dense(256, activation='selu'))
model.add(Dropout(0.50))

#Last Dense Layer
model.add(Dense(no_of_classes, activation='softmax'))

optimizer=Adam(lr=0.0001)
model.compile(optimizer =optimizer , loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

from tensorflow.keras.utils import plot_model
from IPython.display import Image
plot_model(model, show_shapes=True,show_layer_names=True)

y_test.shape

model1=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=35,batch_size=batch_size)

model.evaluate(x_test,y_test)

model.save('model.h5')
model.load('model.h5')

import cv2
import numpy as np

img = cv2.imread("/content/affectnet-training-data/fear/image0000285.jpg",0)
img = cv2.resize(img, (96, 96))
img = np.reshape(img, [1, 96, 96, 1])
print(np.argmax(model.predict(img)))

y_pred = np.argmax(model.predict(x_test))
y_true = np.argmax(y_test)
print("y predict is: ",y_pred," y true is: ",y_true)

def emotion(em):
  if(em == 0):
    print("anger")
  elif(em==1):
    print("contempt")
  elif(em==2):
    print("disgust")
  elif(em==3):
    print("fear")
  elif(em==4):
    print("happy")
  elif(em==5):
    print("neutral")
  elif (em==6):
    print("sad")
  elif (em==7):
    print("surprise")
  return em

import cv2
img = cv2.imread("/content/affectnet-training-data/surprise/ffhq_108.png",0)
img = cv2.resize(img, (96, 96))
img = np.reshape(img, [1, 96, 96, 1])
print("The emotion is: ")
pred=emotion(np.argmax(model.predict(img)))

plt.plot(model1.history['accuracy'],label='accuracy')
plt.plot(model1.history['val_accuracy'],label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

plt.plot(model1.history['loss'],label='loss')
plt.plot(model1.history['val_loss'],label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='lower right')
plt.show()

from keras.optimizers import Adam,SGD,RMSprop

model_2 = Sequential()

model_2.add(Conv2D(32, (3,3), activation="relu", input_shape = (picture_size,picture_size,1)))
model_2.add(Conv2D(32, (3,3), activation="relu", input_shape = (picture_size,picture_size,1)))
model_2.add(BatchNormalization())
model_2.add(MaxPooling2D(pool_size = (2,2), strides = 2))
model_2.add(Dropout(0.50))

model_2.add(Conv2D(64, (3,3), activation="relu"))
model_2.add(Conv2D(64, (3,3), activation="relu"))
model_2.add(BatchNormalization())
model_2.add(MaxPooling2D(pool_size = (2,2), strides = 2))
model_2.add(Dropout(0.50))

model_2.add(Conv2D(128, (3,3), activation="relu"))
model_2.add(Conv2D(128, (3,3), activation="relu"))
model_2.add(BatchNormalization())
model_2.add(MaxPooling2D(pool_size = (2,2), strides = 2))
model_2.add(Dropout(0.50))

model_2.add(Flatten())
model_2.add(Dense(256, activation='relu', kernel_regularizer="l2"))
model_2.add(BatchNormalization())
model_2.add(Dropout(0.50))
model_2.add(Dense(8, activation='softmax'))

model_2.compile(optimizer = Adam(learning_rate=0.001), loss='SparseCategoricalCrossentropy', metrics=['accuracy'])

model_2.summary()

model2=model_2.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=32)

model_2.evaluate(x_test,y_test)

plt.plot(model2.history['accuracy'],label='accuracy')
plt.plot(model2.history['val_accuracy'],label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

plt.plot(model2.history['loss'],label='loss')
plt.plot(model2.history['val_loss'],label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='lower right')
plt.show()